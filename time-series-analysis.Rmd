---
title: 'Unravelling Urban Traffic Dynamics: A Time-Series Analysis'
author: "Claire Bentzen"
date: '2023-11-15'
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
library(ggplot2)
library(dplyr)
```

## Introduction
```{r}
# read in traffic data
traffic <- read.csv("traffic.csv")
traffic

# convert date column to datetime
traffic$DateTime <- as.POSIXct(traffic$DateTime, format="%Y-%m-%d %H:%M:%S")

# convert Junction column to categorical
traffic$Junction <- factor(traffic$Junction)
```

```{r}
# check for missing values by column
colSums(is.na(traffic))

# remove NAs from dataframe
traffic <- na.omit(traffic)

# check for duplicate rows
sum(duplicated(traffic))
```

## Exploratory Data Analysis 
### Explore Vehicle Counts Aggregated by Day
```{r, warning=FALSE, message=FALSE}
# aggregate by date
traffic$Date <- as.Date(traffic$DateTime)

# group by Date and Junction, then calculate daily counts
traffic_daily <- traffic %>%
  group_by(Date, Junction) %>%
  summarize(DailyCount = sum(Vehicles))

# plot daily vehicle counts
ggplot(traffic_daily, aes(x = Date, y = DailyCount, color = Junction)) +
  geom_line() +
  labs(title = "Daily Vehicles Counts by Junction",
       x = "Date",
       y = "Vehicle Count",
       color = "Junction") +
  theme_minimal()
```

### Explore Vehicle Counts by Hour
```{r, warning=FALSE}
# plot hourly vehicle counts
ggplot(traffic, aes(x = DateTime, y = Vehicles, color = Junction)) +
  geom_line() +
  labs(title = "Hourly Vehicles Counts by Junction",
       x = "DateTime",
       y = "Vehicles",
       color = "Junction") +
  theme_minimal()
```

```{r}
# average vehicle counts grouped by Junction
vehicle_avg <- traffic %>%
  group_by(Junction) %>%
  summarize(AvgVehicleCount = mean(Vehicles))
vehicle_avg
```

### Time Series Plot by Junction
```{r, warning=FALSE, message=FALSE}
# split data into each junction
traffic1 <- traffic[traffic$Junction == 1, ]
traffic2 <- traffic[traffic$Junction == 2, ]
traffic3 <- traffic[traffic$Junction == 3, ]
traffic4 <- traffic[traffic$Junction == 4, ]

# plot each junction vehicle counts
par(mfrow = c(2, 2))

# junction 1 time series
traffic1.ts <- ts(traffic1$Vehicles, frequency = 24)
plot.ts(traffic1.ts, xlab = "Time", ylab = "Vehicle Count", main = "Junction 1 TS Plot of Vehicles") 

# junction 2 time series
traffic2.ts <- ts(traffic2$Vehicles, frequency = 24)
plot.ts(traffic2.ts, xlab = "Time", ylab = "Vehicle Count", main = "Junction 2 TS Plot of Vehicles") 

# junction 3 time series
traffic3.ts <- ts(traffic3$Vehicles, frequency = 24)
plot.ts(traffic3.ts, xlab = "Time", ylab = "Vehicle Count", main = "Junction 3 TS Plot of Vehicles") 

# junction 4 time series
traffic4.ts <- ts(traffic4$Vehicles, frequency = 24)
plot.ts(traffic4.ts, xlab = "Time", ylab = "Vehicle Count", main = "Junction 4 TS Plot of Vehicles") 
```



```{r}
# Convert Date column to Date object
traffic$Date <- as.Date(traffic$Date)

# Extract day of week from Date
traffic$DayOfWeek <- weekdays(traffic$Date)

# Plot average daily vehicle counts by day of week
library(ggplot2)

ggplot(traffic, aes(x = DayOfWeek, y = Vehicles, fill = Junction)) +
  geom_boxplot() +
  labs(title = "Average Daily Vehicle Counts by Day of Week",
       x = "Day of Week",
       y = "Vehicle Count",
       fill = "Junction") +
  theme_minimal()
```
```{r}
# Extract month from Date
traffic$Month <- format(traffic$Date, "%B")

# Plot average monthly vehicle counts
ggplot(traffic, aes(x = Month, y = Vehicles, fill = Junction)) +
  geom_bar(stat = "summary", fun = "mean") +
  labs(title = "Average Monthly Vehicle Counts",
       x = "Month",
       y = "Average Vehicle Count",
       fill = "Junction") +
  theme_minimal()
```
```{r}
# Create a binary variable indicating weekday or weekend
traffic$DayType <- ifelse(weekdays(traffic$Date) %in% c("Saturday", "Sunday"), "Weekend", "Weekday")

# Plot average daily vehicle counts by day type
ggplot(traffic, aes(x = DayType, y = Vehicles, fill = Junction)) +
  geom_boxplot() +
  labs(title = "Average Daily Vehicle Counts by Day Type",
       x = "Day Type",
       y = "Vehicle Count",
       fill = "Junction") +
  theme_minimal()
```

```{r}
# Convert DateTime to POSIXct
traffic$DateTime <- as.POSIXct(traffic$DateTime, format="%Y-%m-%d %H:%M:%S")

# Calculate lagged variables for each Junction
library(dplyr)

traffic_lagged <- traffic %>%
  group_by(Junction) %>%
  arrange(DateTime) %>%
  mutate(Vehicles_Lag1 = lag(Vehicles),
         Vehicles_Lag2 = lag(Vehicles, 2),
         Vehicles_Lag3 = lag(Vehicles, 3))

# Filter out rows with missing lagged values
traffic_lagged <- filter(traffic_lagged, complete.cases(Vehicles, Vehicles_Lag1, Vehicles_Lag2, Vehicles_Lag3))

# Ensure 'traffic_lagged' is a data frame
traffic_lagged <- as.data.frame(traffic_lagged)

# Check for infinite values
if (any(is.infinite(unlist(traffic_lagged)))) {
  stop("Infinite values detected in the data.")
}

# Calculate correlation matrix for the lagged vehicle counts of different Junctions
cor_matrix_junctions <- cor(traffic_lagged %>%
                              select(starts_with("Vehicles_Lag")), use = "pairwise.complete.obs")

# Plot the correlation matrix as a heatmap
library(corrplot)
corrplot(cor_matrix_junctions, method = "color", type = "upper", order = "hclust", tl.cex = 0.7)
```


```{r}

# Convert DateTime to POSIXct
traffic$DateTime <- as.POSIXct(traffic$DateTime, format="%Y-%m-%d %H:%M:%S")

# Create a time series object
traffic_ts <- ts(traffic$Vehicles, frequency = 24)

# Time Series Decomposition
decomposition <- decompose(traffic_ts)

# Plot the original time series
par(mfrow = c(3, 1))
plot(traffic_ts, main = "Original Time Series", ylab = "Vehicle Count")

# Plot the trend component
plot(decomposition$trend, main = "Trend Component", ylab = "Trend")

# Plot the seasonal component
plot(decomposition$seasonal, main = "Seasonal Component", ylab = "Seasonal")

# Plot the remainder (residuals) component
plot(decomposition$random, main = "Residuals (Remainder) Component", ylab = "Residuals")

```

```{r}

library(lubridate)
library(dplyr)
library(ggplot2)
library(lubridate)

# Look at hour of day for weekends 

# Convert DateTime to a datetime object
traffic$DateTime <- as.POSIXct(traffic$DateTime, format="%Y-%m-%d %H:%M:%S")

# Create a new column for the hour of the day
traffic$HourOfDay <- format(traffic$DateTime, "%H")

# Convert HourOfDay to numeric for plotting purposes
traffic$HourOfDay <- as.numeric(traffic$HourOfDay)

# Create a new column for the day of the week
traffic$DayOfWeek <- weekdays(traffic$DateTime)

# Filter data to include only weekends
traffic_weekends <- traffic[traffic$DayOfWeek %in% c("Saturday", "Sunday"), ]

# Plot the average number of vehicles for each hour on weekends
library(ggplot2)
ggplot(traffic_weekends, aes(x = HourOfDay, y = Vehicles)) +
  geom_point() +
  stat_summary(fun.y = "mean", geom = "point", col = "red", size = 3) +
  labs(x = "Hour of Day", y = "Average Number of Vehicles", title = "Average Vehicles by Hour on Weekends") +
  theme_minimal()
```

```{r}
# Weekdays hour of day

# Convert DateTime to a datetime object
traffic$DateTime <- as.POSIXct(traffic$DateTime, format="%Y-%m-%d %H:%M:%S")

# Create a new column for the hour of the day
traffic$HourOfDay <- format(traffic$DateTime, "%H")

# Convert HourOfDay to numeric for plotting purposes
traffic$HourOfDay <- as.numeric(traffic$HourOfDay)

# Create a new column for the day of the week
traffic$DayOfWeek <- weekdays(traffic$DateTime)

# Filter data to include only weekdays
traffic_weekdays <- traffic[traffic$DayOfWeek %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"), ]

# Plot the average number of vehicles for each hour on weekdays
library(ggplot2)
ggplot(traffic_weekdays, aes(x = HourOfDay, y = Vehicles)) +
  geom_point() +
  stat_summary(fun.y = "mean", geom = "point", col = "red", size = 3) +
  labs(x = "Hour of Day", y = "Average Number of Vehicles", title = "Average Vehicles by Hour on Weekdays") +
  theme_minimal()


```

```{r}
# Differencing 

library(lubridate)

traffic$DateTime <- as.POSIXct(traffic$DateTime)

# Create a time series object for junctions 1 and 2
ts_junction1 <- ts(traffic$Vehicles[traffic$Junction == 1], frequency = 24)  # Assuming hourly data
ts_junction2 <- ts(traffic$Vehicles[traffic$Junction == 2], frequency = 24)  # Assuming hourly data

# Differencing to remove seasonality
diff_junction1 <- diff(ts_junction1)
diff_junction2 <- diff(ts_junction2)

# Create a new time series with DateTime
ts_diff_junction1 <- ts(diff_junction1, start = start(ts_junction1), frequency = frequency(ts_junction1))
ts_diff_junction2 <- ts(diff_junction2, start = start(ts_junction2), frequency = frequency(ts_junction2))

# Plot the differenced time series for Junctions 1 and 2
plot.new()
plot(ts_diff_junction1, type = "l", col = "blue",
     xlab = "Date and Time", ylab = "Differenced Number of Vehicles",
     main = "Differenced Time Series to Remove Seasonality: Junction 1")
lines(ts_diff_junction2, col = "red")
legend("topright", legend = c("Junction 1", "Junction 2"), col = c("blue", "red"), lty = 1)
```


```{r}

#Split into Junction 1,2,3 and perform log transformation

library(dplyr)

traffic <- read.csv("traffic.csv")
traffic <- traffic %>%
  select(-ID)

traffic

# Convert DateTime column to POSIXct
traffic$DateTime <- as.POSIXct(traffic$DateTime)

# Filter out Junction 4
filtered_traffic <- traffic %>%
  filter(Junction != 4)

# Split the data into Junctions 1, 2, and 3
junction1_data <- filtered_traffic %>%
  filter(Junction == 1)

junction2_data <- filtered_traffic %>%
  filter(Junction == 2)

junction3_data <- filtered_traffic %>%
  filter(Junction == 3)


# Function to perform log transformation on the "Vehicles" column
log_transformation_function <- function(data) {
  data$Vehicles_log <- log1p(data$Vehicles)
  return(data)
}

# Apply log transformation to each junction dataset
junction1_data <- log_transformation_function(junction1_data)
junction2_data <- log_transformation_function(junction2_data)
junction3_data <- log_transformation_function(junction3_data)

# Print the updated data frames
cat("\nJunction 1 Data with Log Transformation:\n")
print(junction1_data)

cat("\nJunction 2 Data with Log Transformation:\n")
print(junction2_data)

cat("\nJunction 3 Data with Log Transformation:\n")
print(junction3_data)


```

```{r}
# Function to perform differencing on the "Vehicles" column
difference_function <- function(data) {
  data$Vehicles_diff <- c(NA, diff(data$Vehicles))
  return(data)
}

# Apply differencing to each junction dataset
junction1_data <- difference_function(junction1_data)
junction2_data <- difference_function(junction2_data)
junction3_data <- difference_function(junction3_data)

# Print the updated data frames
cat("\nJunction 1 Data with Differencing:\n")
print(junction1_data)

cat("\nJunction 2 Data with Differencing:\n")
print(junction2_data)

cat("\nJunction 3 Data with Differencing:\n")
print(junction3_data)

```

```{r}
#  train/test split
train_test_split_function <- function(data, train_percentage = 0.8) {
  split_index <- round(nrow(data) * train_percentage)
  train_set <- data[1:split_index, ]
  test_set <- data[(split_index + 1):nrow(data), ]
  return(list(train_set = train_set, test_set = test_set))
}

# Apply train/test split to each junction dataset
split_junction1 <- train_test_split_function(junction1_data)
split_junction2 <- train_test_split_function(junction2_data)
split_junction3 <- train_test_split_function(junction3_data)

# Access the training and testing sets for each junction
train_junction1 <- split_junction1$train_set
test_junction1 <- split_junction1$test_set

train_junction2 <- split_junction2$train_set
test_junction2 <- split_junction2$test_set

train_junction3 <- split_junction3$train_set
test_junction3 <- split_junction3$test_set

train_junction1

# Print the dimensions of the training and testing sets for each junction
cat("\nJunction 1 Training Set Dimensions:\n")
print(dim(train_junction1))
cat("\nJunction 1 Testing Set Dimensions:\n")
print(dim(test_junction1))

cat("\nJunction 2 Training Set Dimensions:\n")
print(dim(train_junction2))
cat("\nJunction 2 Testing Set Dimensions:\n")
print(dim(test_junction2))

cat("\nJunction 3 Training Set Dimensions:\n")
print(dim(train_junction3))
cat("\nJunction 3 Testing Set Dimensions:\n")
print(dim(test_junction3))
# #Train/test split 
# 
# # Set the percentage of data for training (e.g., 80%)
# train_percentage <- 0.8
# 
# # Calculate the index to split the data
# split_index <- round(nrow(traffic) * train_percentage)
# 
# # Create training and testing sets
# train_data <- traffic[1:split_index, ]
# test_data <- traffic[(split_index + 1):nrow(traffic), ]

```

## Modeling




```{r}

#MOVING AVERAGE MODEL

library(ggplot2)
# Function to calculate MAE, MSE, and RMSE
calculate_errors <- function(predictions, actual) {
  errors <- predictions - actual
  mae <- mean(abs(errors), na.rm = TRUE)
  mse <- mean(errors^2, na.rm = TRUE)
  rmse <- sqrt(mse)
  return(c(MAE = mae, MSE = mse, RMSE = rmse))
}

# Function to calculate Simple Moving Average
calculate_sma <- function(data, window_size) {
  sma_values <- zoo::rollmean(data, k = window_size, fill = NA, align = "right")
  return(sma_values)
}

# Function to create plots for each junction
create_plots <- function(train_data, test_data, junction_number, window_size = 3) {
  train_data$SMA <- calculate_sma(train_data$Vehicles, window_size)
  test_data$SMA <- calculate_sma(test_data$Vehicles, window_size)
  
  ggplot() +
    geom_line(data = train_data, aes(x = DateTime, y = Vehicles, color = "Training Data")) +
    geom_line(data = test_data, aes(x = DateTime, y = Vehicles, color = "Test Data")) +
    geom_line(data = test_data, aes(x = DateTime, y = SMA, color = "Predictions")) +
    labs(title = paste("Simple Moving Average Model - Junction", junction_number),
         x = "DateTime",
         y = "Number of Vehicles") +
    scale_color_manual(values = c("Training Data" = "blue", "Test Data" = "green", "Predictions" = "red")) +
    theme_minimal()
}

# Apply Simple Moving Average and create plots for each junction
junctions <- list(junction1 = list(train_data = train_junction1, test_data = test_junction1),
                  junction2 = list(train_data = train_junction2, test_data = test_junction2),
                  junction3 = list(train_data = train_junction3, test_data = test_junction3))

for (junction_name in names(junctions)) {
  plot_data <- junctions[[junction_name]]
  plot <- create_plots(plot_data$train_data, plot_data$test_data, junction_number = substr(junction_name, nchar(junction_name), nchar(junction_name)))
  print(plot)
}




```

```{r}
library(ggplot2)

# Function to calculate MAE, MSE, and RMSE
calculate_errors <- function(predictions, actual) {
  errors <- predictions - actual
  mae <- mean(abs(errors), na.rm = TRUE)
  mse <- mean(errors^2, na.rm = TRUE)
  rmse <- sqrt(mse)
  return(c(MA = mae, MSE = mse, RMSE = rmse))
}

# Function to calculate Simple Moving Average
calculate_sma <- function(data, window_size) {
  sma_values <- zoo::rollmean(data, k = window_size, fill = NA, align = "right")
  return(sma_values)
}

# Initialize an empty dataframe to store errors
total_errors <- data.frame(Junction = character(0), MA = numeric(0), MSE = numeric(0), RMSE = numeric(0))

# Apply Simple Moving Average and accumulate errors for each junction
junctions <- list(junction1 = list(train_data = train_junction1, test_data = test_junction1),
                  junction2 = list(train_data = train_junction2, test_data = test_junction2),
                  junction3 = list(train_data = train_junction3, test_data = test_junction3))

for (junction_name in names(junctions)) {
  plot_data <- junctions[[junction_name]]
  
  # Calculate SMA for test data using Vehicles_log
  plot_data$test_data$SMA <- calculate_sma(plot_data$test_data$Vehicles_log, window_size)
  
  # Calculate errors for the current junction using Vehicles_log
  errors <- calculate_errors(plot_data$test_data$SMA, plot_data$test_data$Vehicles_log)
  
  # Add junction name to errors
  errors <- cbind(Junction = junction_name, errors)
  
  # Accumulate errors in the total_errors dataframe
  total_errors <- rbind(total_errors, data.frame(errors))
  
  # Print errors for the current junction
  cat("Junction", junction_name, "Errors:\n")
  print(errors)
  
  # Create plots using Vehicles_log
  plot <- create_plots(plot_data$train_data, plot_data$test_data, junction_number = substr(junction_name, nchar(junction_name), nchar(junction_name)))
  print(plot)
}


# Print the final dataframe with errors for all junctions
print("Total Errors:")
print(total_errors)

total_errors

```


```{r}
library(forecast)

# Seasonal Naive Model

# Set the percentage of data for training (e.g., 80%)
  train_percentage <- 0.8

# Initialize a list to store models and predictions for each junction
junction_models_sn <- list()
junction_predictions_sn <- list()

# Define a function for fitting and forecasting
fit_sn_model <- function(train_data, test_data) {
  # Fit a Seasonal Naive model
  sn_model <- snaive(train_data, h = length(test_data))
  
  # Make predictions on the test set
  predictions_sn <- forecast(sn_model)
  
  # Return the model and predictions
  return(list(model = sn_model, predictions = predictions_sn))
}

# Initialize a list to store models and predictions for each junction
junction_models_sn <- list()
junction_predictions_sn <- list()

# Define a function for fitting and forecasting
fit_sn_model <- function(train_data, test_data) {
  # Fit a Seasonal Naive model
  sn_model <- snaive(train_data, h = length(test_data))
  
  # Make predictions on the test set
  predictions_sn <- forecast(sn_model)
  
  # Return the model and predictions
  return(list(model = sn_model, predictions = predictions_sn))
}

# Iterate over each junction
for (j in 1:3) {
  # Get the train and test data for the current junction
  train_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
  test_data <- eval(parse(text = paste0("test_junction", j, "$Vehicles_log")))
  
  # Fit the Seasonal Naive model
  result_junction <- fit_sn_model(train_data, test_data)
  
  # Save the model and predictions in the lists
  junction_models_sn[[as.character(j)]] <- result_junction$model
  junction_predictions_sn[[as.character(j)]] <- result_junction$predictions
}

# # Plotting
# par(mfrow = c(2, 2))  # 2x2 layout for the plots
# 
# for (j in 1:3) {
#   # Get the data and predictions for the current junction
#   junction_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
#   predictions_sn <- junction_predictions_sn[[as.character(j)]]
#   
#   # Plotting
#   plot(junction_data, col = "blue", main = paste("Junction ", j, ": Actual vs. Predicted"), xlab = "DateTime", ylab = "Vehicles_log")
#   lines(predictions_sn$mean, col = "red", lty = 2)
#   legend("topright", legend = c("Actual", "Predicted"), col = c("blue", "red"), lty = 2:1, cex = 0.5, inset = 0.02)
# }

```


```{r}
# ARIMA Model
# Function to calculate MAE, MSE, and RMSE
calculate_metrics <- function(actual, forecast) {
  errors <- actual - forecast
  mae <- mean(abs(errors), na.rm = TRUE)
  mse <- mean(errors^2, na.rm = TRUE)
  rmse <- sqrt(mse)
  
  return(c(MAE = mae, MSE = mse, RMSE = rmse))
}

# ARIMA Model
# Initialize lists to store models, predictions, and metrics for each junction
junction_models_arima <- list()
junction_predictions_arima <- list()
junction_metrics_arima <- list()

# Define a function for fitting and forecasting ARIMA
fit_arima_model <- function(train_data, test_data) {
  # Fit an ARIMA model
  arima_model <- Arima(train_data, order = c(1, 1, 1))
  
  # Make predictions on the test set
  predictions_arima <- forecast(arima_model, h = length(test_data))
  
  # Calculate metrics
  metrics <- calculate_metrics(test_data, predictions_arima$mean)
  
  # Return the model, predictions, and metrics
  return(list(model = arima_model, predictions = predictions_arima, metrics = metrics))
}

# Initialize an empty dataframe to store metrics
total_metrics_arima <- data.frame(Junction = character(0), MAE = numeric(0), MSE = numeric(0), RMSE = numeric(0))

# Iterate over each junction
for (j in 1:3) {
  # Get the train and test data for the current junction
  train_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
  test_data <- eval(parse(text = paste0("test_junction", j, "$Vehicles_log")))
  
  # Fit the ARIMA model
  result_junction_arima <- fit_arima_model(train_data, test_data)
  
  # Save the model, predictions, and metrics in the lists
  junction_models_arima[[as.character(j)]] <- result_junction_arima$model
  junction_predictions_arima[[as.character(j)]] <- result_junction_arima$predictions
  junction_metrics_arima[[as.character(j)]] <- result_junction_arima$metrics
  
  # Add junction name to metrics
  metrics <- cbind(Junction = as.character(j), result_junction_arima$metrics)
  
  # Accumulate metrics in the total_metrics_arima dataframe
  total_metrics_arima <- rbind(total_metrics_arima, data.frame(metrics))
}

# Print the metrics for each junction with ARIMA
for (j in 1:3) {
  cat("\nMetrics for Junction", j, "with ARIMA:\n")
  print(junction_metrics_arima[[as.character(j)]])
}

# Print the final dataframe with metrics for all junctions with ARIMA
print("Total Metrics ARIMA:")
print(total_metrics_arima)

```

```{r}

# SARIMA Model

# Initialize lists to store models, predictions, and metrics for each junction
junction_models_sarima <- list()
junction_predictions_sarima <- list()
junction_metrics_sarima <- list()

# Define a function for fitting and forecasting SARIMA
fit_sarima_model <- function(train_data, test_data) {
  # Fit a SARIMA model
  sarima_model <- Arima(train_data, order = c(1, 1, 1), seasonal = list(order = c(1, 1, 1), period = 12))
  
  # Make predictions on the test set
  predictions_sarima <- forecast(sarima_model, h = length(test_data))
  
  # Calculate metrics
  metrics <- calculate_metrics(test_data, predictions_sarima$mean)
  
  # Return the model, predictions, and metrics
  return(list(model = sarima_model, predictions = predictions_sarima, metrics = metrics))
}

# Initialize an empty dataframe to store metrics
total_metrics_sarima <- data.frame(Junction = character(0), MAE = numeric(0), MSE = numeric(0), RMSE = numeric(0))

# Iterate over each junction
for (j in 1:3) {
  # Get the train and test data for the current junction
  train_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
  test_data <- eval(parse(text = paste0("test_junction", j, "$Vehicles_log")))
  
  # Fit the SARIMA model
  result_junction_sarima <- fit_sarima_model(train_data, test_data)
  
  # Save the model, predictions, and metrics in the lists
  junction_models_sarima[[as.character(j)]] <- result_junction_sarima$model
  junction_predictions_sarima[[as.character(j)]] <- result_junction_sarima$predictions
  junction_metrics_sarima[[as.character(j)]] <- result_junction_sarima$metrics
  
  # Add junction name to metrics
  metrics <- cbind(Junction = as.character(j), result_junction_sarima$metrics)
  
  # Accumulate metrics in the total_metrics_sarima dataframe
  total_metrics_sarima <- rbind(total_metrics_sarima, data.frame(metrics))
}

# Print the metrics for each junction with SARIMA
for (j in 1:3) {
  cat("\nMetrics for Junction", j, "with SARIMA:\n")
  print(junction_metrics_sarima[[as.character(j)]])
}

# Print the final dataframe with metrics for all junctions with SARIMA
print("Total Metrics SARIMA:")
print(total_metrics_sarima)

```


```{r}
#Evaluation Metrics to Seasonal Naive

# Function to calculate MAE, MSE, and RMSE
calculate_metrics <- function(actual, forecast) {
  errors <- actual - forecast
  mae <- mean(abs(errors), na.rm = TRUE)
  mse <- mean(errors^2, na.rm = TRUE)
  rmse <- sqrt(mse)
  
  return(c(MAE = mae, MSE = mse, RMSE = rmse))
}

# Seasonal Naive Model

# Set the percentage of data for training (e.g., 80%)
train_percentage <- 0.8

# Initialize a list to store models and predictions for each junction
junction_models_sn <- list()
junction_predictions_sn <- list()
junction_metrics <- list()

# Define a function for fitting and forecasting
fit_sn_model <- function(train_data, test_data) {
  # Fit a Seasonal Naive model
  sn_model <- snaive(train_data, h = length(test_data))
  
  # Make predictions on the test set
  predictions_sn <- forecast(sn_model)
  
  # Calculate metrics
  metrics <- calculate_metrics(test_data, predictions_sn$mean)
  
  # Return the model, predictions, and metrics
  return(list(model = sn_model, predictions = predictions_sn, metrics = metrics))
}

# Iterate over each junction
for (j in 1:3) {
  # Get the train and test data for the current junction
  train_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
  test_data <- eval(parse(text = paste0("test_junction", j, "$Vehicles_log")))
  
  # Fit the Seasonal Naive model
  result_junction <- fit_sn_model(train_data, test_data)
  
  # Save the model, predictions, and metrics in the lists
  junction_models_sn[[as.character(j)]] <- result_junction$model
  junction_predictions_sn[[as.character(j)]] <- result_junction$predictions
  junction_metrics[[as.character(j)]] <- result_junction$metrics
}

# Print the metrics for each junction
for (j in 1:3) {
  cat("\nMetrics for Junction", j, ":\n")
  print(junction_metrics[[as.character(j)]])
}








# Evaluation Metrics to Seasonal Naive

# Function to calculate MAE, MSE, and RMSE
calculate_metrics <- function(actual, forecast) {
  errors <- actual - forecast
  mae <- mean(abs(errors), na.rm = TRUE)
  mse <- mean(errors^2, na.rm = TRUE)
  rmse <- sqrt(mse)
  
  return(c(MAE = mae, MSE = mse, RMSE = rmse))
}

# Seasonal Naive Model

# Set the percentage of data for training (e.g., 80%)
train_percentage <- 0.8

# Initialize lists to store models, predictions, and metrics for each junction
junction_models_sn <- list()
junction_predictions_sn <- list()
junction_metrics <- list()

# Define a function for fitting and forecasting
fit_sn_model <- function(train_data, test_data) {
  # Fit a Seasonal Naive model
  sn_model <- snaive(train_data, h = length(test_data))
  
  # Make predictions on the test set
  predictions_sn <- forecast(sn_model)
  
  # Calculate metrics
  metrics <- calculate_metrics(test_data, predictions_sn$mean)
  
  # Return the model, predictions, and metrics
  return(list(model = sn_model, predictions = predictions_sn, metrics = metrics))
}

# Initialize an empty dataframe to store metrics
total_metrics_sn <- data.frame(Junction = character(0), MAE = numeric(0), MSE = numeric(0), RMSE = numeric(0))

# Iterate over each junction
for (j in 1:3) {
  # Get the train and test data for the current junction
  train_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
  test_data <- eval(parse(text = paste0("test_junction", j, "$Vehicles_log")))
  
  # Fit the Seasonal Naive model
  result_junction <- fit_sn_model(train_data, test_data)
  
  # Save the model, predictions, and metrics in the lists
  junction_models_sn[[as.character(j)]] <- result_junction$model
  junction_predictions_sn[[as.character(j)]] <- result_junction$predictions
  junction_metrics[[as.character(j)]] <- result_junction$metrics
  
  # Add junction name to metrics
  metrics <- cbind(Junction = as.character(j), result_junction$metrics)
  
  # Accumulate metrics in the total_metrics_sn dataframe
  total_metrics_sn <- rbind(total_metrics_sn, data.frame(metrics))
}

# Print the metrics for each junction
for (j in 1:3) {
  cat("\nMetrics for Junction", j, ":\n")
  print(junction_metrics[[as.character(j)]])
}

# Print the final dataframe with metrics for all junctions
print("Total Metrics SN:")
print(total_metrics_sn)


```






```{r}

#plotting ARIMA predictions
plot_arima_predictions <- function(train_data, test_data, predictions, junction_num, line_width = 0.75, plot_width = 10, plot_height = 5) {
  # Convert DateTime to a Date class for plotting
  train_data$DateTime <- as.Date(train_data$DateTime)
  test_data$DateTime <- as.Date(test_data$DateTime)
  
  # Set plot size
  options(repr.plot.width = plot_width, repr.plot.height = plot_height)
  
  # Plot the time series, training data, and predictions
  plot(train_data$DateTime, train_data$Vehicles_log, type = "o", col = "blue", lwd = line_width,
       xlab = "Date", ylab = "Vehicles_log", main = paste("ARIMA Predictions - Junction", junction_num))
  
  # Add test data to the plot
  points(test_data$DateTime, test_data$Vehicles_log, type = "o", col = "orange", lwd = line_width)
  
  # Add predictions to the plot
  lines(test_data$DateTime, predictions$mean, col = "red", lty = 5, lwd = line_width)
  
# Add legend with smaller text size
legend("topleft", legend = c("Train Data", "Test Data", "Predictions"), 
       col = c("blue", "orange", "red"), lty = c(1, 1, 2), lwd = line_width * 2, cex = 1)
}

# Iterate over each junction to plot ARIMA predictions
for (j in 1:3) {
  # Get the train, test data, and predictions for the current junction
  train_data <- eval(parse(text = paste0("train_junction", j)))
  test_data <- eval(parse(text = paste0("test_junction", j)))
  predictions <- junction_predictions_arima[[as.character(j)]]
  
  # Plot ARIMA predictions with adjusted parameters
  plot_arima_predictions(train_data, test_data, predictions, junction_num = j, line_width = 1, plot_width = 20, plot_height = 7)
}


```
```{r}


```


```{r}
# # Load required libraries
# library(ggplot2)
# library(gridExtra)
# 
# 
# # Data for ARIMA model
# mae_arima <- c(0.3126863, 0.2921633, 0.4216769)
# mse_arima <- c(0.1345307, 0.1192132, 0.2687715)
# rmse_arima <- c(0.3667842, 0.3452727, 0.518431)
# 
# # Data for SARIMA model
# mae_sarima <- c(0.3159922, 0.5405169, 0.4228157)
# mse_sarima <- c(0.1408275, 0.4326395, 0.2936567)
# rmse_sarima <- c(0.3752699, 0.6577534, 0.5419010)
# 
# # Data for Seasonal Naive model
# mae_seasonal_naive <- c(0.3128057, 0.3079644, 0.4236349)
# mse_seasonal_naive <- c(0.1339939, 0.1405705, 0.2792485)
# rmse_seasonal_naive <- c(0.3660518, 0.3749273, 0.5284397)
# 
# # Create a data frame for ARIMA model
# data_arima <- data.frame(Junction = c("Junction 1", "Junction 2", "Junction 3"),
#                          Model = rep("ARIMA", 3),
#                          MAE = mae_arima, MSE = mse_arima, RMSE = rmse_arima)
# 
# # Create a data frame for SARIMA model
# data_sarima <- data.frame(Junction = c("Junction 1", "Junction 2", "Junction 3"),
#                           Model = rep("SARIMA", 3),
#                           MAE = mae_sarima, MSE = mse_sarima, RMSE = rmse_sarima)
# 
# # Create a data frame for Seasonal Naive model
# data_seasonal_naive <- data.frame(Junction = c("Junction 1", "Junction 2", "Junction 3"),
#                                   Model = rep("Seasonal Naive", 3),
#                                   MAE = mae_seasonal_naive, MSE = mse_seasonal_naive, RMSE = rmse_seasonal_naive)
# # Data for Moving Average model
# mae_ma <- c(0.04817959, 0.1047791, 0.1375423)
# mse_ma <- c(0.004186767, 0.01859385, 0.03324423)
# rmse_ma <- c(0.06470523, 0.1363593, 0.18233)
# 
# # Create a data frame for Moving Average model
# data_ma <- data.frame(Junction = c("Junction 1", "Junction 2", "Junction 3"),
#                       Model = rep("Moving Average", 3),
#                       MAE = mae_ma, MSE = mse_ma, RMSE = rmse_ma)
# 
# # Combine all data frames including Moving Average model
# data_combined_all <- rbind(data_arima, data_sarima, data_seasonal_naive, data_ma)
# 
# # Function to create a grouped bar chart for all models with increased font size and fixed scales
# create_grouped_bar_chart_all <- function(metric, title) {
#   ggplot(data_combined_all, aes(x = Junction, y = get(metric), fill = Model)) +
#     geom_bar(stat = "identity", position = "dodge") +
#     labs(title = title, y = metric) +
#     theme_minimal() +
#     theme(legend.text = element_text(size = 12),  
#           legend.title = element_text(size = 15, face = "bold"),  
#           plot.title = element_text(size = 18, face = "bold")) +  
#     facet_wrap(~Model, scales = "fixed", ncol = 2)
# }
# 
# # Print the faceted bar chart for all metrics with increased font size and fixed scales
# print(create_grouped_bar_chart_all("MAE", "MAE Comparison (ARIMA, SARIMA, Seasonal Naive, Moving Average)"))
# print(create_grouped_bar_chart_all("MSE", "MSE Comparison (ARIMA, SARIMA, Seasonal Naive, Moving Average)"))
# print(create_grouped_bar_chart_all("RMSE", "RMSE Comparison (ARIMA, SARIMA, Seasonal Naive, Moving Average)"))
# 
# 
# 
# 
# 
# # # Combine all data frames
# # data_combined <- rbind(data_arima, data_sarima, data_seasonal_naive)
# # # 
# # # Function to create a grouped bar chart for all models with increased font size
# # create_grouped_bar_chart_all <- function(metric, title) {
# #   ggplot(data_combined, aes(x = Junction, y = get(metric), fill = Model)) +
# #     geom_bar(stat = "identity", position = "dodge") +
# #     labs(title = title, y = metric) +
# #     theme_minimal() +
# #     theme(legend.text = element_text(size = 12),
# #           legend.title = element_text(size = 15, face = "bold"),
# #           plot.title = element_text(size = 18, face = "bold")) +
# #     facet_wrap(~Model, scales = "free_y", ncol = 3)
# # }
# # 
# # # Print the faceted bar chart for all metrics with increased font size
# # print(create_grouped_bar_chart_all("MAE", "MAE Comparison (ARIMA, SARIMA, Seasonal Naive)"))
# # print(create_grouped_bar_chart_all("MSE", "MSE Comparison (ARIMA, SARIMA, Seasonal Naive)"))
# # print(create_grouped_bar_chart_all("RMSE", "RMSE Comparison (ARIMA, SARIMA, Seasonal Naive)"))
# 
# ```
# ```{r}
# library(dplyr)
# library(tidyr)
# # Combine the data frames
# data_combined <- rbind(data_arima, data_sarima, data_seasonal_naive)
# 
# # Pivot the data for better table creation
# data_table <- pivot_longer(data_combined, cols = c(MAE, MSE, RMSE), names_to = "Metric", values_to = "Value")
# 
# # Spread the data to create separate columns for each metric
# summary_table <- spread(data_table, Metric, Value)
# 
# # Print the summary table
# print(summary_table)
# 
# ```
# ```{r}
# # Load required library
# library(knitr)
# 
# # Combine data into a data frame
# metrics_table <- data.frame(
#   Junction = rep(c("Junction 1", "Junction 2", "Junction 3"), each = 4),
#   Model = rep(c("ARIMA", "SARIMA", "Seasonal Naive", "Moving Average"), times = 3),
#   MAE = c(0.3126863, 0.2921633, 0.4216769, 0.04817959,
#           0.3159922, 0.5405169, 0.4228157, 0.1047791,
#           0.3128057, 0.3079644, 0.4236349, 0.1375423),
#   MSE = c(0.1345307, 0.1192132, 0.2687715, 0.004186767,
#           0.1408275, 0.4326395, 0.2936567, 0.01859385,
#           0.1339939, 0.1405705, 0.2792485, 0.03324423),
#   RMSE = c(0.3667842, 0.3452727, 0.518431, 0.06470523,
#            0.3752699, 0.6577534, 0.5419010, 0.1363593,
#            0.3660518, 0.3749273, 0.5284397, 0.18233)
# )
# 
# # Print the table
# kable(metrics_table, "markdown")
# 
# 
# 
# 



```
 
