---
title: 'Unravelling Urban Traffic Dynamics: A Time-Series Analysis'
author: "Claire Bentzen"
date: '2023-11-15'
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
library(ggplot2)
library(dplyr)
```

## Introduction
```{r}
# read in traffic data
traffic <- read.csv("traffic.csv")
traffic

# convert date column to datetime
traffic$DateTime <- as.POSIXct(traffic$DateTime, format="%Y-%m-%d %H:%M:%S")

# convert Junction column to categorical
traffic$Junction <- factor(traffic$Junction)
```

```{r}
# check for missing values by column
colSums(is.na(traffic))

# remove NAs from dataframe
traffic <- na.omit(traffic)

# check for duplicate rows
sum(duplicated(traffic))
```

## Exploratory Data Analysis 
### Explore Vehicle Counts Aggregated by Day
```{r, warning=FALSE, message=FALSE}
# aggregate by date
traffic$Date <- as.Date(traffic$DateTime)

# group by Date and Junction, then calculate daily counts
traffic_daily <- traffic %>%
  group_by(Date, Junction) %>%
  summarize(DailyCount = sum(Vehicles))

# plot daily vehicle counts
ggplot(traffic_daily, aes(x = Date, y = DailyCount, color = Junction)) +
  geom_line() +
  labs(title = "Daily Vehicles Counts by Junction",
       x = "Date",
       y = "Vehicle Count",
       color = "Junction") +
  theme_minimal()
```

### Explore Vehicle Counts by Hour
```{r, warning=FALSE}
# plot hourly vehicle counts
ggplot(traffic, aes(x = DateTime, y = Vehicles, color = Junction)) +
  geom_line() +
  labs(title = "Hourly Vehicles Counts by Junction",
       x = "DateTime",
       y = "Vehicles",
       color = "Junction") +
  theme_minimal()
```

```{r}
# average vehicle counts grouped by Junction
vehicle_avg <- traffic %>%
  group_by(Junction) %>%
  summarize(AvgVehicleCount = mean(Vehicles))
vehicle_avg
```

### Time Series Plot by Junction
```{r, warning=FALSE, message=FALSE}
# split data into each junction
traffic1 <- traffic[traffic$Junction == 1, ]
traffic2 <- traffic[traffic$Junction == 2, ]
traffic3 <- traffic[traffic$Junction == 3, ]
traffic4 <- traffic[traffic$Junction == 4, ]

# plot each junction vehicle counts
par(mfrow = c(2, 2))

# junction 1 time series
traffic1.ts <- ts(traffic1$Vehicles, frequency = 24)
plot.ts(traffic1.ts, xlab = "Time", ylab = "Vehicle Count", main = "Junction 1 TS Plot of Vehicles") 

# junction 2 time series
traffic2.ts <- ts(traffic2$Vehicles, frequency = 24)
plot.ts(traffic2.ts, xlab = "Time", ylab = "Vehicle Count", main = "Junction 2 TS Plot of Vehicles") 

# junction 3 time series
traffic3.ts <- ts(traffic3$Vehicles, frequency = 24)
plot.ts(traffic3.ts, xlab = "Time", ylab = "Vehicle Count", main = "Junction 3 TS Plot of Vehicles") 

# junction 4 time series
traffic4.ts <- ts(traffic4$Vehicles, frequency = 24)
plot.ts(traffic4.ts, xlab = "Time", ylab = "Vehicle Count", main = "Junction 4 TS Plot of Vehicles") 
```



```{r}
# Convert Date column to Date object
traffic$Date <- as.Date(traffic$Date)

# Extract day of week from Date
traffic$DayOfWeek <- weekdays(traffic$Date)

# Plot average daily vehicle counts by day of week
library(ggplot2)

ggplot(traffic, aes(x = DayOfWeek, y = Vehicles, fill = Junction)) +
  geom_boxplot() +
  labs(title = "Average Daily Vehicle Counts by Day of Week",
       x = "Day of Week",
       y = "Vehicle Count",
       fill = "Junction") +
  theme_minimal()
```
```{r}
# Extract month from Date
traffic$Month <- format(traffic$Date, "%B")

# Plot average monthly vehicle counts
ggplot(traffic, aes(x = Month, y = Vehicles, fill = Junction)) +
  geom_bar(stat = "summary", fun = "mean") +
  labs(title = "Average Monthly Vehicle Counts",
       x = "Month",
       y = "Average Vehicle Count",
       fill = "Junction") +
  theme_minimal()
```
```{r}
# Create a binary variable indicating weekday or weekend
traffic$DayType <- ifelse(weekdays(traffic$Date) %in% c("Saturday", "Sunday"), "Weekend", "Weekday")

# Plot average daily vehicle counts by day type
ggplot(traffic, aes(x = DayType, y = Vehicles, fill = Junction)) +
  geom_boxplot() +
  labs(title = "Average Daily Vehicle Counts by Day Type",
       x = "Day Type",
       y = "Vehicle Count",
       fill = "Junction") +
  theme_minimal()
```

```{r}
# Convert DateTime to POSIXct
traffic$DateTime <- as.POSIXct(traffic$DateTime, format="%Y-%m-%d %H:%M:%S")

# Calculate lagged variables for each Junction
library(dplyr)

traffic_lagged <- traffic %>%
  group_by(Junction) %>%
  arrange(DateTime) %>%
  mutate(Vehicles_Lag1 = lag(Vehicles),
         Vehicles_Lag2 = lag(Vehicles, 2),
         Vehicles_Lag3 = lag(Vehicles, 3))

# Filter out rows with missing lagged values
traffic_lagged <- filter(traffic_lagged, complete.cases(Vehicles, Vehicles_Lag1, Vehicles_Lag2, Vehicles_Lag3))

# Ensure 'traffic_lagged' is a data frame
traffic_lagged <- as.data.frame(traffic_lagged)

# Check for infinite values
if (any(is.infinite(unlist(traffic_lagged)))) {
  stop("Infinite values detected in the data.")
}

# Calculate correlation matrix for the lagged vehicle counts of different Junctions
cor_matrix_junctions <- cor(traffic_lagged %>%
                              select(starts_with("Vehicles_Lag")), use = "pairwise.complete.obs")

# Plot the correlation matrix as a heatmap
library(corrplot)
corrplot(cor_matrix_junctions, method = "color", type = "upper", order = "hclust", tl.cex = 0.7)
```
```{r}

# Convert DateTime to POSIXct
traffic$DateTime <- as.POSIXct(traffic$DateTime, format="%Y-%m-%d %H:%M:%S")

# Create a time series object
traffic_ts <- ts(traffic$Vehicles, frequency = 24)

# Time Series Decomposition
decomposition <- decompose(traffic_ts)

# Plot the original time series
par(mfrow = c(3, 1))
plot(traffic_ts, main = "Original Time Series", ylab = "Vehicle Count")

# Plot the trend component
plot(decomposition$trend, main = "Trend Component", ylab = "Trend")

# Plot the seasonal component
plot(decomposition$seasonal, main = "Seasonal Component", ylab = "Seasonal")

# Plot the remainder (residuals) component
plot(decomposition$random, main = "Residuals (Remainder) Component", ylab = "Residuals")

```

```{r}

library(lubridate)
library(dplyr)
library(ggplot2)
library(lubridate)

# Look at hour of day for weekends 

# Convert DateTime to a datetime object
traffic$DateTime <- as.POSIXct(traffic$DateTime, format="%Y-%m-%d %H:%M:%S")

# Create a new column for the hour of the day
traffic$HourOfDay <- format(traffic$DateTime, "%H")

# Convert HourOfDay to numeric for plotting purposes
traffic$HourOfDay <- as.numeric(traffic$HourOfDay)

# Create a new column for the day of the week
traffic$DayOfWeek <- weekdays(traffic$DateTime)

# Filter data to include only weekends
traffic_weekends <- traffic[traffic$DayOfWeek %in% c("Saturday", "Sunday"), ]

# Plot the average number of vehicles for each hour on weekends
library(ggplot2)
ggplot(traffic_weekends, aes(x = HourOfDay, y = Vehicles)) +
  geom_point() +
  stat_summary(fun.y = "mean", geom = "point", col = "red", size = 3) +
  labs(x = "Hour of Day", y = "Average Number of Vehicles", title = "Average Vehicles by Hour on Weekends") +
  theme_minimal()
```

```{r}
# Weekdays hour of day

# Convert DateTime to a datetime object
traffic$DateTime <- as.POSIXct(traffic$DateTime, format="%Y-%m-%d %H:%M:%S")

# Create a new column for the hour of the day
traffic$HourOfDay <- format(traffic$DateTime, "%H")

# Convert HourOfDay to numeric for plotting purposes
traffic$HourOfDay <- as.numeric(traffic$HourOfDay)

# Create a new column for the day of the week
traffic$DayOfWeek <- weekdays(traffic$DateTime)

# Filter data to include only weekdays
traffic_weekdays <- traffic[traffic$DayOfWeek %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"), ]

# Plot the average number of vehicles for each hour on weekdays
library(ggplot2)
ggplot(traffic_weekdays, aes(x = HourOfDay, y = Vehicles)) +
  geom_point() +
  stat_summary(fun.y = "mean", geom = "point", col = "red", size = 3) +
  labs(x = "Hour of Day", y = "Average Number of Vehicles", title = "Average Vehicles by Hour on Weekdays") +
  theme_minimal()


```

```{r}
# Differencing 

library(lubridate)

traffic$DateTime <- as.POSIXct(traffic$DateTime)

# Create a time series object for junctions 1 and 2
ts_junction1 <- ts(traffic$Vehicles[traffic$Junction == 1], frequency = 24)  # Assuming hourly data
ts_junction2 <- ts(traffic$Vehicles[traffic$Junction == 2], frequency = 24)  # Assuming hourly data

# Differencing to remove seasonality
diff_junction1 <- diff(ts_junction1)
diff_junction2 <- diff(ts_junction2)

# Create a new time series with DateTime
ts_diff_junction1 <- ts(diff_junction1, start = start(ts_junction1), frequency = frequency(ts_junction1))
ts_diff_junction2 <- ts(diff_junction2, start = start(ts_junction2), frequency = frequency(ts_junction2))

# Plot the differenced time series for Junctions 1 and 2
plot.new()
plot(ts_diff_junction1, type = "l", col = "blue",
     xlab = "Date and Time", ylab = "Differenced Number of Vehicles",
     main = "Differenced Time Series to Remove Seasonality: Junction 1")
lines(ts_diff_junction2, col = "red")
legend("topright", legend = c("Junction 1", "Junction 2"), col = c("blue", "red"), lty = 1)
```


```{r}
library(dplyr)

traffic <- read.csv("traffic.csv")
traffic <- traffic %>%
  select(-ID)

traffic

# Convert DateTime column to POSIXct
traffic$DateTime <- as.POSIXct(traffic$DateTime)

# Filter out Junction 4
filtered_traffic <- traffic %>%
  filter(Junction != 4)

# Split the data into Junctions 1, 2, and 3
junction1_data <- filtered_traffic %>%
  filter(Junction == 1)

junction2_data <- filtered_traffic %>%
  filter(Junction == 2)

junction3_data <- filtered_traffic %>%
  filter(Junction == 3)


# Function to perform log transformation on the "Vehicles" column
log_transformation_function <- function(data) {
  data$Vehicles_log <- log1p(data$Vehicles)
  return(data)
}

# Apply log transformation to each junction dataset
junction1_data <- log_transformation_function(junction1_data)
junction2_data <- log_transformation_function(junction2_data)
junction3_data <- log_transformation_function(junction3_data)

# Print the updated data frames
cat("\nJunction 1 Data with Log Transformation:\n")
print(junction1_data)

cat("\nJunction 2 Data with Log Transformation:\n")
print(junction2_data)

cat("\nJunction 3 Data with Log Transformation:\n")
print(junction3_data)


```

```{r}
# Function to perform differencing on the "Vehicles" column
difference_function <- function(data) {
  data$Vehicles_diff <- c(NA, diff(data$Vehicles))
  return(data)
}

# Apply differencing to each junction dataset
junction1_data <- difference_function(junction1_data)
junction2_data <- difference_function(junction2_data)
junction3_data <- difference_function(junction3_data)

# Print the updated data frames
cat("\nJunction 1 Data with Differencing:\n")
print(junction1_data)

cat("\nJunction 2 Data with Differencing:\n")
print(junction2_data)

cat("\nJunction 3 Data with Differencing:\n")
print(junction3_data)

```

```{r}
#  train/test split
train_test_split_function <- function(data, train_percentage = 0.8) {
  split_index <- round(nrow(data) * train_percentage)
  train_set <- data[1:split_index, ]
  test_set <- data[(split_index + 1):nrow(data), ]
  return(list(train_set = train_set, test_set = test_set))
}

# Apply train/test split to each junction dataset
split_junction1 <- train_test_split_function(junction1_data)
split_junction2 <- train_test_split_function(junction2_data)
split_junction3 <- train_test_split_function(junction3_data)

# Access the training and testing sets for each junction
train_junction1 <- split_junction1$train_set
test_junction1 <- split_junction1$test_set

train_junction2 <- split_junction2$train_set
test_junction2 <- split_junction2$test_set

train_junction3 <- split_junction3$train_set
test_junction3 <- split_junction3$test_set

train_junction1

# Print the dimensions of the training and testing sets for each junction
cat("\nJunction 1 Training Set Dimensions:\n")
print(dim(train_junction1))
cat("\nJunction 1 Testing Set Dimensions:\n")
print(dim(test_junction1))

cat("\nJunction 2 Training Set Dimensions:\n")
print(dim(train_junction2))
cat("\nJunction 2 Testing Set Dimensions:\n")
print(dim(test_junction2))

cat("\nJunction 3 Training Set Dimensions:\n")
print(dim(train_junction3))
cat("\nJunction 3 Testing Set Dimensions:\n")
print(dim(test_junction3))
# #Train/test split 
# 
# # Set the percentage of data for training (e.g., 80%)
# train_percentage <- 0.8
# 
# # Calculate the index to split the data
# split_index <- round(nrow(traffic) * train_percentage)
# 
# # Create training and testing sets
# train_data <- traffic[1:split_index, ]
# test_data <- traffic[(split_index + 1):nrow(traffic), ]

```


```{r}
# library(ggplot2)
# 
# # Combine training and test data for plotting
# combined_data <- rbind(
#   transform(train_data, set = "Training Set"),
#   transform(test_data, set = "Test Set")
# )
# 
# # Plotting the combined data
# ggplot(combined_data, aes(x = DateTime, y = Vehicles_diff, color = set)) +
#   geom_line() +
#   labs(title = "Training and Test Sets", x = "Date and Time", y = "Vehicles Difference")

```
## Modeling



```{r}

# Function to calculate moving average for a given data frame and column
moving_average_function <- function(data, column_name, window_size) {
  data[[paste0(column_name, "_ma")]] <- zoo::rollmean(data[[column_name]], k = window_size, fill = NA)
  return(data)
}

# Apply moving average to each junction dataset
window_size <- 3  # Adjust the window size as needed

junction1_data <- moving_average_function(junction1_data, "Vehicles_log", window_size)
junction2_data <- moving_average_function(junction2_data, "Vehicles_log", window_size)
junction3_data <- moving_average_function(junction3_data, "Vehicles_log", window_size)

library(ggplot2)

junction1_data

# Set the width of the plots
plot_width <- 8

library(ggplot2)
library(cowplot)

# Set the width of the plots
plot_width <- 8

# Plot for Junction 1
ggplot(junction1_data, aes(x = DateTime_J1)) +
  geom_line(aes(y = Vehicles_log_J1, color = "Original"), size = 1, alpha = 0.8) +
  geom_line(aes(y = Vehicles_log_ma_J1, color = "Moving Average"), linetype = "dashed", size = 0.3) +
  labs(title = "Time Series with Moving Averages - Junction 1",
       x = "DateTime",
       y = "Vehicles_log_J1") +
  theme_minimal() +
  scale_color_manual(values = c("Original" = "blue", "Moving Average" = "red")) +
  theme(legend.position = "top", legend.text = element_text(size = 19))

# Plot for Junction 2
ggplot(junction2_data, aes(x = DateTime_J2)) +
  geom_line(aes(y = Vehicles_log_J2, color = "Original"), size = 1, alpha = 0.8) +
  geom_line(aes(y = Vehicles_log_ma_J2, color = "Moving Average"), linetype = "dashed", size = 0.3) +
  labs(title = "Time Series with Moving Averages - Junction 2",
       x = "DateTime",
       y = "Vehicles_log_J2") +
  theme_minimal() +
  scale_color_manual(values = c("Original" = "blue", "Moving Average" = "red")) +
  theme(legend.position = "top",  legend.text = element_text(size = 19))

# Plot for Junction 3
ggplot(junction3_data, aes(x = DateTime_J3)) +
  geom_line(aes(y = Vehicles_log_J3, color = "Original"), size = 1, alpha = 0.8) +
  geom_line(aes(y = Vehicles_log_ma_J3, color = "Moving Average"), linetype = "dashed", size = 0.3) +
  labs(title = "Time Series with Moving Averages - Junction 3",
       x = "DateTime",
       y = "Vehicles_log_J3") +
  theme_minimal() +
  scale_color_manual(values = c("Original" = "blue", "Moving Average" = "red")) +
  theme(legend.position = "top",  legend.text = element_text(size = 19))


```

```{r}
library(forecast)

# Seasonal Naive Model

# Set the percentage of data for training (e.g., 80%)
train_percentage <- 0.8

# Initialize a list to store models and predictions for each junction
junction_models_sn <- list()
junction_predictions_sn <- list()

# Define a function for fitting and forecasting
fit_sn_model <- function(train_data, test_data) {
  # Fit a Seasonal Naive model
  sn_model <- snaive(train_data, h = length(test_data))
  
  # Make predictions on the test set
  predictions_sn <- forecast(sn_model)
  
  # Return the model and predictions
  return(list(model = sn_model, predictions = predictions_sn))
}

# Iterate over each junction
for (j in 1:3) {
  # Get the train and test data for the current junction
  train_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
  test_data <- eval(parse(text = paste0("test_junction", j, "$Vehicles_log")))
  
  # Fit the Seasonal Naive model
  result_junction <- fit_sn_model(train_data, test_data)
  
  # Save the model and predictions in the lists
  junction_models_sn[[as.character(j)]] <- result_junction$model
  junction_predictions_sn[[as.character(j)]] <- result_junction$predictions
}

# Plotting
par(mfrow = c(2, 2))  # 2x2 layout for the plots

for (j in 1:3) {
  # Get the data and predictions for the current junction
  junction_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
  predictions_sn <- junction_predictions_sn[[as.character(j)]]
  
  # Plotting
  plot(junction_data, col = "blue", main = paste("Junction ", j, ": Actual vs. Predicted"), xlab = "DateTime", ylab = "Vehicles_log")
  lines(predictions_sn$mean, col = "red", lty = 2)
  legend("topright", legend = c("Actual", "Predicted"), col = c("blue", "red"), lty = 2:1, cex = 0.5, inset = 0.02)
}

```



```{r}
# # Seasonal Naive Model
# 
# library(forecast)
# 
# # Convert your 'DateTime' column to a time series
# ts_data <- ts(traffic$Vehicles_diff, frequency = 1)
# 
# # Set the percentage of data for training (e.g., 80%)
# train_percentage <- 0.8
# 
# # Initialize a list to store models and predictions for each junction
# junction_models_sn <- list()
# junction_predictions_sn <- list()
# 
# # Iterate over each junction
# for (j in unique(traffic$Junction)) {
#   # Subset the data for the current junction
#   junction_data <- subset(traffic, Junction == j)$Vehicles_diff
#   ts_junction_data <- ts(junction_data, frequency = 1)
#   
#   # Calculate the index to split the data
#   split_index <- round(length(ts_junction_data) * train_percentage)
#   
#   # Create training and testing sets
#   train_data <- window(ts_junction_data, end = split_index)
#   test_data <- window(ts_junction_data, start = split_index + 1)
#   
#   # Fit an Seasonal Naive model
#   sn_model <- snaive(train_data, h = length(test_data))
#   
#   # Save the model in the list
#   junction_models_sn[[as.character(j)]] <- sn_model
#   
#   # Make predictions on the test set
#   predictions_sn <- forecast(sn_model)
#   
#   # Save the predictions in the list
#   junction_predictions_sn[[as.character(j)]] <- predictions_sn
# }
# 
# par(mfrow = c(2, 2))  # 2x2 layout for the plots
# 
# for (j in unique(traffic$Junction)) {
#   junction_data <- subset(traffic, Junction == j)$Vehicles_diff
#   ts_junction_data <- ts(junction_data, frequency = 1)
#   predictions_sn <- junction_predictions_sn[[as.character(j)]]
#   
#   plot(ts_junction_data, col = "blue", main = paste("Junction ", j, ": Actual vs. Predicted"), xlab = "DateTime", ylab = "Vehicles Difference")
#   lines(predictions_sn$mean, col = "red", lty = 2)
#   legend("topright", legend = c("Actual", "Predicted"), col = c("blue", "red"), lty = 2:1, cex = 0.5, inset = 0.02)
# }
```

```{r}
# ARIMA Model
# Function to calculate MAE, MSE, and RMSE
calculate_metrics <- function(actual, forecast) {
  errors <- actual - forecast
  mae <- mean(abs(errors), na.rm = TRUE)
  mse <- mean(errors^2, na.rm = TRUE)
  rmse <- sqrt(mse)
  
  return(c(MAE = mae, MSE = mse, RMSE = rmse))
}

# ARIMA Model

# Initialize a list to store models and predictions for each junction
junction_models_arima <- list()
junction_predictions_arima <- list()
junction_metrics_arima <- list()

# Define a function for fitting and forecasting ARIMA
fit_arima_model <- function(train_data, test_data) {
  # Fit an ARIMA model
arima_model <- Arima(train_data, order = c(1, 1, 1))
  
  # Make predictions on the test set
  predictions_arima <- forecast(arima_model, h = length(test_data))
  
  # Calculate metrics
  metrics <- calculate_metrics(test_data, predictions_arima$mean)
  
  # Return the model, predictions, and metrics
  return(list(model = arima_model, predictions = predictions_arima, metrics = metrics))
}

# Iterate over each junction
for (j in 1:3) {
  # Get the train and test data for the current junction
  train_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
  test_data <- eval(parse(text = paste0("test_junction", j, "$Vehicles_log")))
  
  # Fit the ARIMA model
  result_junction_arima <- fit_arima_model(train_data, test_data)
  
  # Save the model, predictions, and metrics in the lists
  junction_models_arima[[as.character(j)]] <- result_junction_arima$model
  junction_predictions_arima[[as.character(j)]] <- result_junction_arima$predictions
  junction_metrics_arima[[as.character(j)]] <- result_junction_arima$metrics
}

# Print the metrics for each junction with ARIMA
for (j in 1:3) {
  cat("\nMetrics for Junction", j, "with ARIMA:\n")
  print(junction_metrics_arima[[as.character(j)]])
}



# 
# # Initialize a list to store models and predictions for each junction
# junction_models <- list()
# junction_predictions <- list()
# 
# # Iterate over each junction
# for (j in unique(traffic$Junction)) {
#   # Subset the data for the current junction
#   junction_data <- subset(traffic, Junction == j)$Vehicles_diff
#   ts_junction_data <- ts(junction_data, frequency = 1)
#   
#   # Calculate the index to split the data
#   split_index <- round(length(ts_junction_data) * train_percentage)
#   
#   # Create training and testing sets
#   train_data <- window(ts_junction_data, end = split_index)
#   test_data <- window(ts_junction_data, start = split_index + 1)
#   
#   # Fit an ARIMA model
#   arima_model <- auto.arima(train_data)
#   
#   # Save the model in the list
#   junction_models[[as.character(j)]] <- arima_model
#   
#   # Make predictions on the test set
#   predictions <- forecast(arima_model, h = length(test_data))
#   
#   # Save the predictions in the list
#   junction_predictions[[as.character(j)]] <- predictions
# }
# 
# 
# 
# # # Plotting only the testing set and predicted values with a smaller legend
# # par(mfrow = c(2, 2))  
# # for (j in unique(traffic$Junction)) {
# #   junction_data <- subset(traffic, Junction == j)$Vehicles_diff
# #   ts_junction_data <- ts(junction_data, frequency = 1)
# #   predictions <- junction_predictions[[as.character(j)]]
# #   
# #   plot(ts_junction_data, col = "blue", main = paste("Junction ", j, ": Actual vs. Predicted"), xlab = "DateTime", ylab = "Vehicles Difference")
# #   lines(predictions$mean, col = "red", lty = 2)
# #   legend("topright", legend = c("Actual", "Predicted"), col = c("blue", "red"), lty = 2:1, cex = 0.5)
# # }
# 
# 
# par(mfrow = c(2, 2))  # 2x2 layout for the plots
# 
# for (j in unique(traffic$Junction)) {
#   junction_data <- subset(traffic, Junction == j)$Vehicles_diff
#   ts_junction_data <- ts(junction_data, frequency = 1)
#   predictions <- junction_predictions[[as.character(j)]]
#   
#   plot(ts_junction_data, col = "blue", main = paste("Junction ", j, ": Actual vs. Predicted"), xlab = "DateTime", ylab = "Vehicles Difference")
#   lines(predictions$mean, col = "red", lty = 2)
#   legend("topright", legend = c("Actual", "Predicted"), col = c("blue", "red"), lty = 2:1, cex = 0.5, inset = 0.02)
# }

```

```{r}

# SARIMA Model

# Initialize a list to store models and predictions for each junction
junction_models_sarima <- list()
junction_predictions_sarima <- list()
junction_metrics_sarima <- list()

# Define a function for fitting and forecasting SARIMA
fit_sarima_model <- function(train_data, test_data) {
  # Fit a SARIMA model
  sarima_model <- Arima(train_data, order = c(1, 1, 1), seasonal = list(order = c(1, 1, 1), period = 12))

  
  # Make predictions on the test set
  predictions_sarima <- forecast(sarima_model, h = length(test_data))
  
  # Calculate metrics
  metrics <- calculate_metrics(test_data, predictions_sarima$mean)
  
  # Return the model, predictions, and metrics
  return(list(model = sarima_model, predictions = predictions_sarima, metrics = metrics))
}

# Iterate over each junction
for (j in 1:3) {
  # Get the train and test data for the current junction
  train_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
  test_data <- eval(parse(text = paste0("test_junction", j, "$Vehicles_log")))
  
  # Fit the SARIMA model
  result_junction_sarima <- fit_sarima_model(train_data, test_data)
  
  # Save the model, predictions, and metrics in the lists
  junction_models_sarima[[as.character(j)]] <- result_junction_sarima$model
  junction_predictions_sarima[[as.character(j)]] <- result_junction_sarima$predictions
  junction_metrics_sarima[[as.character(j)]] <- result_junction_sarima$metrics
}

# Print the metrics for each junction with SARIMA
for (j in 1:3) {
  cat("\nMetrics for Junction", j, "with SARIMA:\n")
  print(junction_metrics_sarima[[as.character(j)]])
}


# #Fit SARIMA model
# library(forecast)
# 
# # Convert your 'DateTime' column to a time series
# ts_data <- ts(traffic$Vehicles, frequency = 1)
# 
# # Initialize a list to store models and predictions for each junction
# junction_models_sarima <- list()
# junction_predictions_sarima <- list()
# 
# # Iterate over each junction
# for (j in unique(traffic$Junction)) {
#   # Subset the data for the current junction
#   junction_data <- subset(traffic, Junction == j)$Vehicles
#   ts_junction_data <- ts(junction_data, frequency = 1)
#   
#   # Calculate the index to split the data
#   split_index <- round(length(ts_junction_data) * train_percentage)
#   
#   # Create training and testing sets
#   train_data <- window(ts_junction_data, end = split_index)
#   test_data <- window(ts_junction_data, start = split_index + 1)
#   
#   # Fit a SARIMA model
#   sarima_model <- auto.arima(train_data, seasonal = TRUE)
# 
#   # Save the model in the list
#   junction_models_sarima[[as.character(j)]] <- sarima_model
#   
#   # Make predictions on the test set
#   predictions_sarima <- forecast(sarima_model)
#   
#   # Save the predictions in the list
#   junction_predictions_sarima[[as.character(j)]] <- predictions_sarima
# }
# 
# par(mfrow = c(2, 2))  # 2x2 layout for the plots
# 
# for (j in unique(traffic$Junction)) {
#   junction_data <- subset(traffic, Junction == j)$Vehicles
#   ts_junction_data <- ts(junction_data, frequency = 1)
#   predictions_sarima <- junction_predictions_sarima[[as.character(j)]]
#   
#   plot(ts_junction_data, col = "blue", main = paste("Junction ", j, ": Actual vs. Predicted"), xlab = "DateTime", ylab = "Vehicles Difference")
#   lines(predictions_sarima$mean, col = "red", lty = 2)
#   legend("topright", legend = c("Actual", "Predicted"), col = c("blue", "red"), lty = 2:1, cex = 0.5, inset = 0.02)
# }
```


```{r}
#Evaluation Metrics to Seasonal Naive

# Function to calculate MAE, MSE, and RMSE
calculate_metrics <- function(actual, forecast) {
  errors <- actual - forecast
  mae <- mean(abs(errors), na.rm = TRUE)
  mse <- mean(errors^2, na.rm = TRUE)
  rmse <- sqrt(mse)
  
  return(c(MAE = mae, MSE = mse, RMSE = rmse))
}

# Seasonal Naive Model

# Set the percentage of data for training (e.g., 80%)
train_percentage <- 0.8

# Initialize a list to store models and predictions for each junction
junction_models_sn <- list()
junction_predictions_sn <- list()
junction_metrics <- list()

# Define a function for fitting and forecasting
fit_sn_model <- function(train_data, test_data) {
  # Fit a Seasonal Naive model
  sn_model <- snaive(train_data, h = length(test_data))
  
  # Make predictions on the test set
  predictions_sn <- forecast(sn_model)
  
  # Calculate metrics
  metrics <- calculate_metrics(test_data, predictions_sn$mean)
  
  # Return the model, predictions, and metrics
  return(list(model = sn_model, predictions = predictions_sn, metrics = metrics))
}

# Iterate over each junction
for (j in 1:3) {
  # Get the train and test data for the current junction
  train_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
  test_data <- eval(parse(text = paste0("test_junction", j, "$Vehicles_log")))
  
  # Fit the Seasonal Naive model
  result_junction <- fit_sn_model(train_data, test_data)
  
  # Save the model, predictions, and metrics in the lists
  junction_models_sn[[as.character(j)]] <- result_junction$model
  junction_predictions_sn[[as.character(j)]] <- result_junction$predictions
  junction_metrics[[as.character(j)]] <- result_junction$metrics
}

# Print the metrics for each junction
for (j in 1:3) {
  cat("\nMetrics for Junction", j, ":\n")
  print(junction_metrics[[as.character(j)]])
}


# if (!requireNamespace("dplyr", quietly = TRUE)) {
#   install.packages("dplyr")
# }
# 
# # Load the dplyr package
# library(dplyr)
# 
# # Initialize an empty data frame for evaluation metrics
# evaluation_metrics_sn <- data.frame(Junction = character(), MAE = numeric(), MSE = numeric(), RMSE = numeric(), stringsAsFactors = FALSE)
# 
# # Calculate evaluation metrics for each junction
# for (j in unique(traffic$Junction)) {
#   junction_data <- subset(traffic, Junction == j)$Vehicles_diff
#   ts_junction_data <- ts(junction_data, frequency = 1)
#   predictions_sn <- junction_predictions_sn[[as.character(j)]]
#   
#   # Extract the actual values from the test set
#   actual_values <- as.vector(window(ts_junction_data, start = length(ts_junction_data) - length(predictions_sn$mean) + 1))
#   
#   # Calculate evaluation metrics
#   mae <- mean(abs(predictions_sn$mean - actual_values))
#   mse <- mean((predictions_sn$mean - actual_values)^2)
#   rmse <- sqrt(mse)
#   
#   # Add the results to the data frame
#   evaluation_metrics_sn <- bind_rows(evaluation_metrics_sn, data.frame(Junction = as.character(j), MAE = mae, MSE = mse, RMSE = rmse))
# }
# 
# # Print the evaluation metrics
# print(evaluation_metrics_sn)

```


```{r}
#Evaluation Metrics to ARIMA 

# Initialize an empty data frame for evaluation metrics
evaluation_metrics <- data.frame(Junction = character(), MAE = numeric(), MSE = numeric(), RMSE = numeric(), stringsAsFactors = FALSE)

# Calculate evaluation metrics for each junction
for (j in unique(traffic$Junction)) {
  junction_data <- subset(traffic, Junction == j)$Vehicles_diff
  ts_junction_data <- ts(junction_data, frequency = 1)
  predictions <- junction_predictions[[as.character(j)]]
  
  # Extract the actual values from the test set
  actual_values <- as.vector(window(ts_junction_data, start = length(ts_junction_data) - length(predictions$mean) + 1))
  
  # Calculate evaluation metrics
  mae <- mean(abs(predictions$mean - actual_values))
  mse <- mean((predictions$mean - actual_values)^2)
  rmse <- sqrt(mse)
  
  # Add the results to the data frame
  evaluation_metrics <- bind_rows(evaluation_metrics, data.frame(Junction = as.character(j), MAE = mae, MSE = mse, RMSE = rmse))
}

# Print the evaluation metrics
print(evaluation_metrics)

```

```{r}
#Evaluation Metrics to SARIMA 

# Initialize an empty data frame for evaluation metrics
evaluation_metrics <- data.frame(Junction = character(), MAE = numeric(), MSE = numeric(), RMSE = numeric(), stringsAsFactors = FALSE)

# Calculate evaluation metrics for each junction
for (j in unique(traffic$Junction)) {
  junction_data <- subset(traffic, Junction == j)$Vehicles
  ts_junction_data <- ts(junction_data, frequency = 1)
  predictions <- junction_predictions[[as.character(j)]]
  
  # Extract the actual values from the test set
  actual_values <- as.vector(window(ts_junction_data, start = length(ts_junction_data) - length(predictions$mean) + 1))
  
  # Calculate evaluation metrics
  mae <- mean(abs(predictions$mean - actual_values))
  mse <- mean((predictions$mean - actual_values)^2)
  rmse <- sqrt(mse)
  
  # Add the results to the data frame
  evaluation_metrics <- bind_rows(evaluation_metrics, data.frame(Junction = as.character(j), MAE = mae, MSE = mse, RMSE = rmse))
}

# Print the evaluation metrics
print(evaluation_metrics)
```

```{r}
library(forecast)

# Define a function for plotting ARIMA predictions
plot_arima_predictions <- function(train_data, test_data, predictions, junction_num) {
  # Combine train and test data for plotting
  plot_data <- rbind(train_data, cbind(test_data, predictions = rep(NA, length(test_data))))
  
  # Convert DateTime to a Date class for plotting
  plot_data$DateTime <- as.Date(plot_data$DateTime)
  
  # Plot the time series, training data, and predictions
  p <- autoplot(plot_data, ts.colour = "blue", ts.linetype = "solid", series = "Train Data") +
    autolayer(plot_data$DateTime, predictions$mean, ts.colour = "red", ts.linetype = "dashed", series = "Predictions") +
    autolayer(plot_data$DateTime, test_data$Vehicles_log, ts.colour = "green", ts.linetype = "solid", series = "Test Data") +
    labs(title = paste("ARIMA Predictions - Junction", junction_num),
         x = "Date",
         y = "Vehicles_log") +
    theme_minimal() +
    theme(legend.position = "top")
  
  return(p)
}

# Iterate over each junction to plot ARIMA predictions
for (j in 1:3) {
  # Get the train, test data, and predictions for the current junction
  train_data <- eval(parse(text = paste0("train_junction", j, "$Vehicles_log")))
  test_data <- eval(parse(text = paste0("test_junction", j, "$Vehicles_log")))
  predictions <- junction_predictions_arima[[as.character(j)]]
  
  # Plot ARIMA predictions
  arima_plot <- plot_arima_predictions(train_data, test_data, predictions, junction_num = j)
  
  # Print the plot
  print(arima_plot)
}

```

